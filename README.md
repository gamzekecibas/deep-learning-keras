# deep-learning-keras
Learning to Deep Learning is in progress! :)
---  
## Examples in the Deep Learning with Python by Fran√ßois Chollet
- [01-binary-classification.ipynb](https://github.com/gamzekecibas/deep-learning-keras/blob/main/01-binary-classification.ipynb): Binary Classification Example with IMDB set.     
- [02-multiclass-classification.ipynb](https://github.com/gamzekecibas/deep-learning-keras/blob/main/02-multiclass-classification.ipynb): Multiclass Classification Example with Reuters set.    
- [03-regression.ipynb](https://github.com/gamzekecibas/deep-learning-keras/blob/main/03-regression.ipynb): Regression Example with Boston Housing set to predict their prices.  
  - *Step 09:* Adding weight regularization (from CH4).  
- [04-binary-classification-iterations.ipynb](https://github.com/gamzekecibas/deep-learning-keras/blob/main/04-binary-classification-iterations.ipynb): Different validations are investigated with Binary Classification Example.  
   - It includes *network size effect* on training and validation loss. It may be important to avoid overfitting or underfitting.  
  - *Dropout Effect* is studied as different dropout rates and its effect on the different size networks (from CH4).
- [05-one-hot-encoding.ipynb](https://github.com/gamzekecibas/deep-learning-keras/blob/main/05-one-hot-encoding.ipynb): One hot encoding is studied as intro to RNN and backpropagation training.
- [06-Using Embedding Layers.ipynb](https://github.com/gamzekecibas/deep-learning-keras/blob/main/06-EmbeddingLayer.ipynb): Introduction to Embedding layers
- [07-implementing-raw-data.ipynb](https://github.com/gamzekecibas/deep-learning-keras/blob/main/07-implementing-raw-data.ipynb): IMDB raw data is used in the script.  
  -   **Please download** [ascIImdb](http://mng.bz/0tIo) and [GloVe 100d](https://www.kaggle.com/danielwillgeorge/glove6b100dtxt) to run the code and **update _dir= r('...')**.         
- [08-recurrent-NN.ipynb](https://github.com/gamzekecibas/deep-learning-keras/blob/main/08-recurrent-NN.ipynb): SimpleRNN method is used with IMDB dataset and there are two iterations with *dropout layer* and *validation split rate*.      
- [09-LSTM-imdb.ipynb](https://github.com/gamzekecibas/deep-learning-keras/blob/main/09-LSTM-imdb.ipynb): Sample LSTM model is created.
- [10-weather-forecasting.ipynb](https://github.com/gamzekecibas/deep-learning-keras/blob/main/10-weather-forecasting.ipynb): Timeseries is worked on the model by jena_climate dataset. LSTM model is trained.   
---  
## In [Practice](https://github.com/gamzekecibas/deep-learning-keras/tree/main/practice):
- [01-basic-perceptron.ipynb](https://github.com/gamzekecibas/deep-learning-keras/blob/main/practice/basic-perceptron.ipynb): The script is presented how an ANN model works fundamentally.
- [02-computer_vision.py](https://github.com/gamzekecibas/deep-learning-keras/blob/main/practice/02-computer_vision.py): Convolutional Neural Network (CNN) study with CIFAR-10 dataset. It is a Google Colab project.
- [03-perceptron-fundamentals](https://github.com/gamzekecibas/deep-learning-keras/blob/main/practice/03-perceptron-fundamentals.ipynb): Fundamentals of neural networks with logical operations by [mcobanov](https://github.com/cobanov)'s study.
