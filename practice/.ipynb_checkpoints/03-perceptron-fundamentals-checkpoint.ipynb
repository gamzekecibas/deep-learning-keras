{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae6d986",
   "metadata": {},
   "source": [
    "## Fundamentals of Neural Network\n",
    "## Logical Operations\n",
    "- https://medium.com/deep-learning-turkiye/bir-sinir-a%C4%9F%C4%B1n%C4%B1-ka%C4%9F%C4%B1da-d%C3%B6kelim-4bb644fa8840\n",
    "- https://github.com/cobanov/NN_Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238030c2",
   "metadata": {},
   "source": [
    "### CONTENT\n",
    "- **Initial Step:** Import required libraries\n",
    "- **01- AND Gate**\n",
    "    - *Step 01:* Data Preparation\n",
    "    - *Step 02:* Model Building\n",
    "    - *Step 03:* Model Running\n",
    "    - *Step 04:* Checking weight and bias values\n",
    "- **02- OR Gate**\n",
    "    - *Step 01:* Data Preparation\n",
    "    - *Step 02:* Model Building\n",
    "    - *Step 03:* Model Running\n",
    "    - *Step 04:* Checking weight and bias values\n",
    "- **03- XOR Gate**\n",
    "    - *Step 01:* Data Preparation\n",
    "    - *Step 02:* Model Building\n",
    "    - *Step 03:* Model Running\n",
    "    - *Step 04:* Checking weight and bias values\n",
    "    - *Step 05:* Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae4acdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL STEP: Import libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f2365f",
   "metadata": {},
   "source": [
    "### 01- AND Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef6ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 01: Data Preparation\n",
    "x_and= np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]], dtype= float)\n",
    "y_and= np.array([[0.0], [0.0], [0.0], [1.0]], dtype= float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277c51c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fadfbaa2b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 02: Model building (2 neurons in 1st layer and 1 neuron in 2nd layer)\n",
    "model_and= keras.Sequential()\n",
    "model_and.add(keras.layers.Dense(units=2, input_shape=[2]))\n",
    "model_and.add(keras.layers.Dense(units=1))\n",
    "\n",
    "model_and.compile(optimizer=\"sgd\", loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "model_and.fit(x_and, y_and, epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d9bc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00374678]]\n",
      "FALSE (0)\n",
      "[[0.20942001]]\n",
      "FALSE (0)\n",
      "[[0.33826324]]\n",
      "FALSE (0)\n",
      "[[0.54393643]]\n",
      "TRUE (1)\n"
     ]
    }
   ],
   "source": [
    "# Step 03: Run the Moddel\n",
    "predictions=[np.array([[0.0, 0.0]]),np.array([[0.0, 1.0]]),np.array([[1.0, 0.0]]),np.array([[1.0, 1.0]])];\n",
    "                                                                                # Only expected true\n",
    "for pAnd in predictions:\n",
    "    res_and= model_and.predict(pAnd)\n",
    "    print(res_and)\n",
    "# If there is a threshold as 0.5:\n",
    "    if res_and > 0.5:\n",
    "        print('TRUE (1)')\n",
    "    else:\n",
    "        print('FALSE (0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90b1d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Weights of 1st Layer\n",
      "[[ 0.7026924  -0.4340978 ]\n",
      " [-0.13106494  0.79050016]]\n",
      "\n",
      "Biases of 1st Layer\n",
      "[ 0.05458199 -0.06955926]\n",
      "\n",
      "Weights of 2nd Layer\n",
      "[[0.7094451 ]\n",
      " [0.37780714]]\n",
      "\n",
      "çBiases of 2nd Layer\n",
      "[-0.00869615]\n"
     ]
    }
   ],
   "source": [
    "# Step 04: Check weights and bias values\n",
    "model_and.summary()\n",
    "first_layer_weights_and = model_and.layers[0].get_weights()[0]\n",
    "first_layer_biases_and  = model_and.layers[0].get_weights()[1]\n",
    "print(\"Weights of 1st Layer\")\n",
    "print(first_layer_weights_and)\n",
    "print(\"\\nBiases of 1st Layer\")\n",
    "print(first_layer_biases_and)\n",
    "\n",
    "second_layer_weights_and = model_and.layers[1].get_weights()[0]\n",
    "second_layer_biases_and  = model_and.layers[1].get_weights()[1]\n",
    "print(\"\\nWeights of 2nd Layer\")\n",
    "print(second_layer_weights_and)\n",
    "print(\"\\nçBiases of 2nd Layer\")\n",
    "print(second_layer_biases_and)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d8cafc",
   "metadata": {},
   "source": [
    "### 02- OR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb7a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 01: Data Preparation\n",
    "x_or= np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]], dtype = float)\n",
    "y_or= np.array([[1.0], [1.0], [0.0], [1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07488082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fae22d08b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 02: Model building\n",
    "model_or= keras.Sequential()\n",
    "model_or.add(keras.layers.Dense(units=2, input_shape=[2]))\n",
    "model_or.add(keras.layers.Dense(units=1))\n",
    "\n",
    "# Model compiling\n",
    "model_or.compile(optimizer='sgd', loss= 'mean_squared_error', metrics=['accuracy'])\n",
    "model_or.fit(x_or, y_or, epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "300a72f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6472644]]\n",
      "TRUE (1)\n",
      "[[1.2234626]]\n",
      "TRUE (1)\n",
      "[[0.25200298]]\n",
      "FALSE (0)\n",
      "[[0.8282012]]\n",
      "TRUE (1)\n"
     ]
    }
   ],
   "source": [
    "# Step 03: Making Predictions\n",
    "# Predictions array is already defined\n",
    "# predictions=[np.array([[0.0, 0.0]]),np.array([[0.0, 1.0]]),np.array([[1.0, 0.0]]),np.array([[1.0, 1.0]])];\n",
    "                                                             # Only expected false\n",
    "for pOr in predictions:\n",
    "    res_or= model_or.predict(pOr)\n",
    "    print(res_or)\n",
    "# If there is a threshold as 0.5:\n",
    "    if res_or > 0.5:\n",
    "        print('TRUE (1)')\n",
    "    else:\n",
    "        print('FALSE (0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1a5701c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "1st layers' weights:  [[ 0.16874225  0.90334344]\n",
      " [ 0.21074238 -0.56013453]]\n",
      "\n",
      "1st layers' biases:  [ 0.3034012  -0.09992693]\n",
      "\n",
      "2nd layers' weights:  [[ 1.049893 ]\n",
      " [-0.6336712]]\n",
      "\n",
      "2nd layers' biases:  [0.2654048]\n"
     ]
    }
   ],
   "source": [
    "# Step 04: Check weights and biases\n",
    "model_or.summary()\n",
    "first_layer_weights_or= model_or.layers[0].get_weights()[0]\n",
    "first_layer_biases_or= model_or.layers[0].get_weights()[1]\n",
    "second_layer_weights_or = model_or.layers[1].get_weights()[0]\n",
    "second_layer_biases_or  = model_or.layers[1].get_weights()[1]\n",
    "\n",
    "print(\"\\n1st layers' weights: \", first_layer_weights_or)\n",
    "print(\"\\n1st layers' biases: \", first_layer_biases_or)\n",
    "print(\"\\n2nd layers' weights: \",second_layer_weights_or)\n",
    "print(\"\\n2nd layers' biases: \",second_layer_biases_or)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614997d",
   "metadata": {},
   "source": [
    "### 03- XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4410b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 01: Data Preparation\n",
    "x_xor = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]], dtype = float)\n",
    "y_xor= np.array([[0],[1],[1],[0]], dtype= float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdabf07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fae235c640>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 02: Model building\n",
    "model_xor= keras.Sequential()\n",
    "model_xor.add(keras.layers.Dense(units=16, input_shape=[2], activation='relu'))\n",
    "model_xor.add(keras.layers.Dense(units=1))\n",
    "\n",
    " # Model compiling\n",
    "model_xor.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
    "model_xor.fit(x_xor, y_xor, epochs= 300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b3d1afb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3564144]]\n",
      "FALSE (0)\n",
      "[[0.85034925]]\n",
      "TRUE (1)\n",
      "[[0.62260926]]\n",
      "TRUE (1)\n",
      "[[0.23755017]]\n",
      "FALSE (0)\n"
     ]
    }
   ],
   "source": [
    "# Step 03: Making Predictions\n",
    "# Predictions array is already defined\n",
    "# predictions=[np.array([[0.0, 0.0]]),np.array([[0.0, 1.0]]),np.array([[1.0, 0.0]]),np.array([[1.0, 1.0]])];\n",
    "                                               # Expected two true (1) values\n",
    "for pXor in predictions:\n",
    "    res_xor = model_xor.predict(pXor)\n",
    "    print(res_xor)\n",
    "# If there is a threshold as 0.5:\n",
    "    if res_xor > 0.5:\n",
    "        print('TRUE (1)')\n",
    "    else:\n",
    "        print('FALSE (0)')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7c78c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 65\n",
      "Trainable params: 65\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "1st layers' weights:  [[-1.4020789e-01 -2.1408299e-01  6.1847914e-02  3.7999164e-02\n",
      "  -4.0421557e-01  6.3446707e-01 -4.6389359e-01 -4.0103203e-01\n",
      "  -3.4730455e-01  3.5287037e-01 -4.0300968e-01 -2.2693868e-01\n",
      "   2.7624062e-01 -2.4375892e-01  2.7091238e-01  2.1255912e-01]\n",
      " [-4.1567197e-01  6.4941227e-02  6.9222637e-02 -5.2079135e-01\n",
      "   4.0360346e-01 -3.0546641e-01 -3.9536655e-02  4.4493130e-01\n",
      "  -5.3150409e-01  4.8850599e-01  4.0978870e-01  1.6425832e-01\n",
      "  -3.1954589e-01  8.7432109e-02  2.9596031e-01 -2.5122566e-04]]\n",
      "\n",
      "1st layers' biases:  [ 0.0000000e+00 -6.6050157e-02 -6.2114801e-02 -4.0505696e-02\n",
      " -1.1421423e-03 -1.0758027e-04  0.0000000e+00 -2.2980761e-02\n",
      "  0.0000000e+00 -3.5264054e-01 -6.6210986e-03 -1.0931919e-01\n",
      " -2.7775946e-01 -8.7644719e-02 -7.4840777e-02 -1.0423087e-01]\n",
      "\n",
      "2nd layers' weights:  [[ 0.23568761]\n",
      " [-0.34347987]\n",
      " [-0.26116616]\n",
      " [-0.43053734]\n",
      " [ 0.7106814 ]\n",
      " [ 0.4649171 ]\n",
      " [ 0.37542927]\n",
      " [ 0.25945377]\n",
      " [ 0.02238494]\n",
      " [-0.4371933 ]\n",
      " [ 0.45504975]\n",
      " [-0.20143738]\n",
      " [-0.44617173]\n",
      " [-0.25648478]\n",
      " [-0.05744554]\n",
      " [-0.16030726]]\n",
      "\n",
      "2nd layers' biases:  [0.3564144]\n"
     ]
    }
   ],
   "source": [
    "# Step 04: Check weights and biases\n",
    "model_xor.summary()\n",
    "first_layer_weights_xor= model_xor.layers[0].get_weights()[0]\n",
    "first_layer_biases_xor= model_xor.layers[0].get_weights()[1]\n",
    "second_layer_weights_xor = model_xor.layers[1].get_weights()[0]\n",
    "second_layer_biases_xor  = model_xor.layers[1].get_weights()[1]\n",
    "\n",
    "print(\"\\n1st layers' weights: \", first_layer_weights_xor)\n",
    "print(\"\\n1st layers' biases: \", first_layer_biases_xor)\n",
    "print(\"\\n2nd layers' weights: \",second_layer_weights_xor)\n",
    "print(\"\\n2nd layers' biases: \",second_layer_biases_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f1c4b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.4828\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4823\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4812\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4800\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4786\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4772\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4757\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4742\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4727\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4722\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4704\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4690\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4679\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4657\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4620\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4608\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4595\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4581\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4568\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4555\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4541\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4527\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4517\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4502\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4491\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4480\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4469\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4458\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4446\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4434\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4422\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4409\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4396\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4384\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4370\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4357\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4344\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4331\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4318\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4306\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4294\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4281\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4269\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4257\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4245\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4233\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4221\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4209\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4196\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4183\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4169\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4156\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4145\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4130\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4118\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4105\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4092\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4079\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4066\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4055\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4040\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4027\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4014\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4001\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3988\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3974\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3961\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3947\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3934\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3922\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3909\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3895\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3882\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3868\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3854\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3841\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3827\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3815\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3801\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3823\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3796\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3790\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3791\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3780\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3758\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3748\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3743\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3738\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3732\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3725\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3717\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3709\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3701\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3695\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3684\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3676\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3668\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3659\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3650\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3641\n",
      "Epoch 104/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3631\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3621\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3611\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3602\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3594\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3586\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3577\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3580\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3561\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3553\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3545\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3542\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3531\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3522\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3528\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3510\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3504\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3497\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3490\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3482\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3476\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3467\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3459\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3451\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3447\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3440\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3433\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3425\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3419\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3413\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3412\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3401\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3394\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3388\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3380\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3381\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3371\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3360\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3354\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3347\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3340\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3347\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3326\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3320\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3316\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3315\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3306\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3301\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3296\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3289\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3282\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3275\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3267\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3259\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3251\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3242\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3234\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3225\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3216\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3212\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3199\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3202\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3194\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3179\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3173\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.3168\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3164\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3157\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3151\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3144\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3137\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3129\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3128\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3114\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3111\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3104\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3095\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3089\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3084\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3077\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3071\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3065\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3057\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3058\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3047\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3037\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3030\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3031\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3018\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3011\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3004\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2997\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2988\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2981\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2972\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2971\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2961\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2952\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2945\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2938\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2931\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2925\n",
      "Epoch 206/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2931\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2912\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2915\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2912\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2899\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2895\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2891\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2885\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2878\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2871\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2863\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2855\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2846\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2837\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2828\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2818\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2809\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2820\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2803\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2793\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2783\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2780\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2775\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2770\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2764\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2757\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2755\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2744\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2737\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2729\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2721\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2712\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2704\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2695\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2687\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2680\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2684\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2668\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2659\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2657\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2653\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2643\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2637\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2631\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2624\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2616\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2607\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2598\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2588\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2577\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2567\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2565\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2551\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2548\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2541\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2536\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2530\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2523\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2516\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2507\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2498\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2489\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2478\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2470\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2469\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2455\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2452\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2442\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2437\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2431\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2424\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2416\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2408\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2399\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2389\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2378\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2369\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2366\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2350\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2348\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2336\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2338\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2321\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2315\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2307\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2299\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2290\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2280\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2273\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2262\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2256\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2246\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2238\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2230\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2220\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2217\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2208\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2201\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2188\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2180\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2173\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2165\n",
      "Epoch 308/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2157\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2148\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2146\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2134\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2123\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2115\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2107\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2099\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2090\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2081\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2071\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2060\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2055\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2041\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2043\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2030\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2017\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2013\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2005\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1997\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1989\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1983\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1973\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1964\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1954\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1944\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1933\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1921\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1919\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1899\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1891\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1890\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1874\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1867\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1858\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1855\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1840\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1831\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1821\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1812\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1806\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1806\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1786\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1779\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1771\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1763\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1771\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1753\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1748\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1744\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1733\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1728\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1722\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1714\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1706\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1696\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1686\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1675\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1663\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1651\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1638\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1648\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1639\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1627\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1610\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1600\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1595\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1593\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1583\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1577\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1569\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1561\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1555\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1546\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1537\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1529\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1520\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1510\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1500\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1490\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1480\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1469\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1465\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1453\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1446\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1431\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1425\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1419\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1413\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1405\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1397\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1389\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1380\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1370\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1360\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1358\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1337\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1328\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1316\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1329\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1321\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1291\n",
      "Epoch 410/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1295\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1286\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1272\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1265\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1257\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1247\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1241\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1229\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1219\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1209\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1209\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1197\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1179\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1171\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1161\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1151\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1141\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1132\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1125\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1113\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1121\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1100\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1101\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1098\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1082\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1078\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1073\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1058\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1049\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1039\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1036\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1019\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1008\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0997\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0985\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0972\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0958\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0949\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0937\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0950\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0917\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0916\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0904\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0900\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0895\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0888\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0881\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0872\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0864\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0853\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0844\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0833\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0821\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0809\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0801\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0789\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0774\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0769\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0753\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0742\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0731\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0726\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0718\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0708\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0696\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0690\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0687\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0675\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0667\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0657\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0657\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0643\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0630\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0621\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0618\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0597\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0581\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0571\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0566\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0556\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0548\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0554\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0528\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0517\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0514\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0499\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0485\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0475\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0488\n",
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 129\n",
      "Trainable params: 129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 05: Iteration\n",
    "# softsign activation\n",
    "model_xor= keras.Sequential()\n",
    "model_xor.add(keras.layers.Dense(units=32, input_shape=[2], activation='softsign'))\n",
    "model_xor.add(keras.layers.Dense(units=1))\n",
    "\n",
    " # Model compiling\n",
    "model_xor.compile(optimizer=\"adam\", loss='mean_absolute_error') \n",
    "history= model_xor.fit(x_xor, y_xor, epochs=500, verbose=1)\n",
    "\n",
    "# Test the model\n",
    "for pXor_1 in predictions:\n",
    "    res_xor_1 = model_xor.predict(pXor_1)\n",
    "    print(np.round(res_xor_1))\n",
    "    \n",
    "print(model_xor.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
